# docker-compose.prod.yml - Production Overrides
services:
  # Production-specific overrides
  model-router:
    build:
      context: .
      dockerfile: docker/model-router.Dockerfile
    environment:
      - LOG_LEVEL=INFO
      - DEBUG_MODE=false
      - WORKERS=4
      - ANTHROPIC_API_KEY=YOUR_ANTHROPIC_API_KEY
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    restart: always
    depends_on:
      mcp-fluentd:
        condition: service_healthy
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "mcp-fluentd:24224"
        tag: "{{.Name}}"

  plan-management:
    build:
      context: .
      dockerfile: docker/plan-management.Dockerfile
    environment:
      - LOG_LEVEL=INFO
      - AUTO_BACKUP=true
      - BACKUP_INTERVAL=1800
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 768M
          cpus: '0.8'
        reservations:
          memory: 384M
          cpus: '0.4'
    restart: always
    depends_on:
      mcp-fluentd:
        condition: service_healthy
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "mcp-fluentd:24224"
        tag: "{{.Name}}"

  git-worktree-manager:
    build:
      context: .
      dockerfile: docker/git-worktree.Dockerfile
    environment:
      - LOG_LEVEL=INFO
      - AUTO_CLEANUP=true
      - CLEANUP_INTERVAL=3600
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.6'
        reservations:
          memory: 256M
          cpus: '0.3'
    restart: always
    depends_on:
      mcp-fluentd:
        condition: service_healthy
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "mcp-fluentd:24224"
        tag: "{{.Name}}"

  workflow-orchestrator:
    build:
      context: .
      dockerfile: docker/workflow-orchestrator.Dockerfile
    environment:
      - LOG_LEVEL=INFO
      - MAX_CONCURRENT_WORKFLOWS=5
      - STEP_TIMEOUT=3600
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    restart: always
    networks:
      - mcp-network
    depends_on:
      mcp-fluentd:
        condition: service_healthy
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "mcp-fluentd:24224"
        tag: "{{.Name}}"

  verification-feedback:
    build:
      context: .
      dockerfile: docker/verification-feedback.Dockerfile
    environment:
      - LOG_LEVEL=INFO
      - STRICT_VERIFICATION=true
      - PARALLEL_VERIFICATION=false
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 768M
          cpus: '0.8'
        reservations:
          memory: 384M
          cpus: '0.4'
    restart: always
    networks:
      - mcp-network
    depends_on:
      mcp-fluentd:
        condition: service_healthy
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "mcp-fluentd:24224"
        tag: "{{.Name}}"

  # Production Redis with persistence
  redis:
    image: redis:7-alpine
    container_name: mcp-redis
    restart: always

    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 300
      --timeout 0

    ports:
      - "6379:6379"

    volumes:
      - redis_data:/data

    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

    depends_on:
      mcp-fluentd:
        condition: service_healthy
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "mcp-fluentd:24224"
        tag: "{{.Name}}"

    networks:
      - mcp-network

    deploy:
      resources:
        limits:
          memory: 768M
          cpus: '0.5'
        reservations:
          memory: 384M
          cpus: '0.25'

  # Production Nginx with SSL
  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx/prod.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      frontend:
        condition: service_healthy
      model-router:
        condition: service_healthy
      plan-management:
        condition: service_healthy
      git-worktree-manager:
        condition: service_healthy
      workflow-orchestrator:
        condition: service_healthy
      verification-feedback:
        condition: service_healthy
      staff-service:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'
    restart: always
    networks:
      - mcp-network
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "mcp-fluentd:24224"
        tag: "{{.Name}}"

  # Customer Frontend React/Next.js Application
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: mcp-frontend
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://nginx/api
      - PORT=3000
    ports:
      - "3002:3000"
    # Remove volume mount to avoid permission issues
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - mcp-network
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "mcp-fluentd:24224"
        tag: "{{.Name}}"
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # Staff Frontend React/Next.js Application
  staff-frontend:
    build:
      context: ./staff-frontend
      dockerfile: Dockerfile
    container_name: mcp-staff-frontend
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://nginx/api/staff
      - PORT=3001
    ports:
      - "3001:3001"
    # Remove volume mount to avoid permission issues
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - mcp-network
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "mcp-fluentd:24224"
        tag: "{{.Name}}"
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # Remove development tools in production
  dev-tools:
    profiles:
      - dev

networks:
  mcp-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.50.0.0/16

volumes:
  redis_data:
    driver: local
  rabbitmq_data:
    driver: local
  postgres_data:
    driver: local
  consul_data:
    driver: local
  plan_storage:
    driver: local
  git_repositories:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local
