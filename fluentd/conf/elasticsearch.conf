# Elasticsearch Configuration for MCP Log Aggregation
# Advanced indexing, mapping, and lifecycle management

# Elasticsearch output configuration with advanced settings
<match mcp.**>
  @type elasticsearch
  @id elasticsearch_main
  host ${ELASTICSEARCH_HOST:-localhost}
  port ${ELASTICSEARCH_PORT:-9200}
  user ${ELASTICSEARCH_USER:-elastic}
  password ${ELASTICSEARCH_PASSWORD:-changeme}
  scheme ${ELASTICSEARCH_SCHEME:-http}
  ssl_verify ${ELASTICSEARCH_SSL_VERIFY:-false}
  
  # Index configuration
  index_name "mcp-logs-${Time.at(time).getutc.strftime('%Y.%m.%d')}"
  type_name "_doc"
  include_tag_key true
  tag_key "@tag"
  
  # Connection management
  reload_connections true
  reconnect_on_error true
  reload_on_failure true
  pool_max 100
  pool_max_per_route 20
  idle_flush_time 30
  request_timeout 60
  
  # Index template configuration
  template_name "mcp-logs-template"
  template_file "/etc/fluentd/templates/mcp-logs-template.json"
  template_overwrite true
  
  # Index lifecycle management
  ilm_enabled true
  ilm_policy_id "mcp-logs-policy"
  ilm_policy_overwrite true
  
  # Advanced buffering
  <buffer>
    @type file
    path /var/log/fluentd/buffer/elasticsearch_main
    flush_mode interval
    flush_interval 10s
    chunk_limit_size 8MB
    total_limit_size 64GB
    flush_thread_count 8
    overflow_action block
    retry_max_times 5
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 60s
    retry_randomize true
    timekey 1h
    timekey_wait 10m
    <secondary>
      @type file
      path /var/log/fluentd/failed/elasticsearch_main
      compress gzip
    </secondary>
  </buffer>
</match>

# Error logs to dedicated index with higher priority
<match mcp.error>
  @type elasticsearch
  @id elasticsearch_error
  host ${ELASTICSEARCH_HOST:-localhost}
  port ${ELASTICSEARCH_PORT:-9200}
  user ${ELASTICSEARCH_USER:-elastic}
  password ${ELASTICSEARCH_PASSWORD:-changeme}
  scheme ${ELASTICSEARCH_SCHEME:-http}
  ssl_verify ${ELASTICSEARCH_SSL_VERIFY:-false}
  
  # Error-specific index configuration
  index_name "mcp-error-logs-${Time.at(time).getutc.strftime('%Y.%m.%d')}"
  type_name "_doc"
  include_tag_key true
  tag_key "@tag"
  
  # Higher priority processing
  reload_connections true
  reconnect_on_error true
  reload_on_failure true
  pool_max 50
  pool_max_per_route 10
  idle_flush_time 10
  request_timeout 30
  
  # Error-specific template
  template_name "mcp-error-logs-template"
  template_file "/etc/fluentd/templates/mcp-error-logs-template.json"
  template_overwrite true
  
  # High-priority buffering
  <buffer>
    @type file
    path /var/log/fluentd/buffer/elasticsearch_error
    flush_mode interval
    flush_interval 5s
    chunk_limit_size 4MB
    total_limit_size 32GB
    flush_thread_count 4
    overflow_action block
    retry_max_times 5
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 30s
    retry_randomize true
    timekey 30m
    timekey_wait 5m
    <secondary>
      @type file
      path /var/log/fluentd/failed/elasticsearch_error
      compress gzip
    </secondary>
  </buffer>
</match>

# Security logs to dedicated index with compliance requirements
<match mcp.security>
  @type elasticsearch
  @id elasticsearch_security
  host ${ELASTICSEARCH_HOST:-localhost}
  port ${ELASTICSEARCH_PORT:-9200}
  user ${ELASTICSEARCH_USER:-elastic}
  password ${ELASTICSEARCH_PASSWORD:-changeme}
  scheme ${ELASTICSEARCH_SCHEME:-http}
  ssl_verify ${ELASTICSEARCH_SSL_VERIFY:-false}
  
  # Security-specific index configuration
  index_name "mcp-security-logs-${Time.at(time).getutc.strftime('%Y.%m.%d')}"
  type_name "_doc"
  include_tag_key true
  tag_key "@tag"
  
  # Security-specific connection settings
  reload_connections true
  reconnect_on_error true
  reload_on_failure true
  pool_max 30
  pool_max_per_route 5
  idle_flush_time 5
  request_timeout 15
  
  # Security-specific template
  template_name "mcp-security-logs-template"
  template_file "/etc/fluentd/templates/mcp-security-logs-template.json"
  template_overwrite true
  
  # Security-specific buffering with immediate flush
  <buffer>
    @type file
    path /var/log/fluentd/buffer/elasticsearch_security
    flush_mode interval
    flush_interval 1s
    chunk_limit_size 2MB
    total_limit_size 16GB
    flush_thread_count 2
    overflow_action block
    retry_max_times 3
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 10s
    retry_randomize true
    timekey 10m
    timekey_wait 1m
    <secondary>
      @type file
      path /var/log/fluentd/failed/elasticsearch_security
      compress gzip
    </secondary>
  </buffer>
</match>

# Performance logs to dedicated index for analytics
<match mcp.performance>
  @type elasticsearch
  @id elasticsearch_performance
  host ${ELASTICSEARCH_HOST:-localhost}
  port ${ELASTICSEARCH_PORT:-9200}
  user ${ELASTICSEARCH_USER:-elastic}
  password ${ELASTICSEARCH_PASSWORD:-changeme}
  scheme ${ELASTICSEARCH_SCHEME:-http}
  ssl_verify ${ELASTICSEARCH_SSL_VERIFY:-false}
  
  # Performance-specific index configuration
  index_name "mcp-performance-logs-${Time.at(time).getutc.strftime('%Y.%m.%d')}"
  type_name "_doc"
  include_tag_key true
  tag_key "@tag"
  
  # Performance-specific connection settings
  reload_connections true
  reconnect_on_error true
  reload_on_failure true
  pool_max 40
  pool_max_per_route 8
  idle_flush_time 15
  request_timeout 30
  
  # Performance-specific template
  template_name "mcp-performance-logs-template"
  template_file "/etc/fluentd/templates/mcp-performance-logs-template.json"
  template_overwrite true
  
  # Performance-specific buffering
  <buffer>
    @type file
    path /var/log/fluentd/buffer/elasticsearch_performance
    flush_mode interval
    flush_interval 10s
    chunk_limit_size 8MB
    total_limit_size 32GB
    flush_thread_count 4
    overflow_action block
    retry_max_times 5
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 60s
    retry_randomize true
    timekey 1h
    timekey_wait 10m
    <secondary>
      @type file
      path /var/log/fluentd/failed/elasticsearch_performance
      compress gzip
    </secondary>
  </buffer>
</match>

# Audit logs to dedicated index with long retention
<match mcp.audit>
  @type elasticsearch
  @id elasticsearch_audit
  host ${ELASTICSEARCH_HOST:-localhost}
  port ${ELASTICSEARCH_PORT:-9200}
  user ${ELASTICSEARCH_USER:-elastic}
  password ${ELASTICSEARCH_PASSWORD:-changeme}
  scheme ${ELASTICSEARCH_SCHEME:-http}
  ssl_verify ${ELASTICSEARCH_SSL_VERIFY:-false}
  
  # Audit-specific index configuration (monthly for long retention)
  index_name "mcp-audit-logs-${Time.at(time).getutc.strftime('%Y.%m')}"
  type_name "_doc"
  include_tag_key true
  tag_key "@tag"
  
  # Audit-specific connection settings
  reload_connections true
  reconnect_on_error true
  reload_on_failure true
  pool_max 20
  pool_max_per_route 4
  idle_flush_time 30
  request_timeout 60
  
  # Audit-specific template
  template_name "mcp-audit-logs-template"
  template_file "/etc/fluentd/templates/mcp-audit-logs-template.json"
  template_overwrite true
  
  # Audit-specific buffering
  <buffer>
    @type file
    path /var/log/fluentd/buffer/elasticsearch_audit
    flush_mode interval
    flush_interval 30s
    chunk_limit_size 4MB
    total_limit_size 16GB
    flush_thread_count 2
    overflow_action block
    retry_max_times 3
    retry_type exponential_backoff
    retry_wait 5s
    retry_max_interval 300s
    retry_randomize true
    timekey 1d
    timekey_wait 1h
    <secondary>
      @type file
      path /var/log/fluentd/failed/elasticsearch_audit
      compress gzip
    </secondary>
  </buffer>
</match>

# Application logs to dedicated index
<match mcp.app>
  @type elasticsearch
  @id elasticsearch_app
  host ${ELASTICSEARCH_HOST:-localhost}
  port ${ELASTICSEARCH_PORT:-9200}
  user ${ELASTICSEARCH_USER:-elastic}
  password ${ELASTICSEARCH_PASSWORD:-changeme}
  scheme ${ELASTICSEARCH_SCHEME:-http}
  ssl_verify ${ELASTICSEARCH_SSL_VERIFY:-false}
  
  # Application-specific index configuration
  index_name "mcp-app-logs-${Time.at(time).getutc.strftime('%Y.%m.%d')}"
  type_name "_doc"
  include_tag_key true
  tag_key "@tag"
  
  # Application-specific connection settings
  reload_connections true
  reconnect_on_error true
  reload_on_failure true
  pool_max 60
  pool_max_per_route 12
  idle_flush_time 20
  request_timeout 45
  
  # Application-specific template
  template_name "mcp-app-logs-template"
  template_file "/etc/fluentd/templates/mcp-app-logs-template.json"
  template_overwrite true
  
  # Application-specific buffering
  <buffer>
    @type file
    path /var/log/fluentd/buffer/elasticsearch_app
    flush_mode interval
    flush_interval 15s
    chunk_limit_size 8MB
    total_limit_size 48GB
    flush_thread_count 6
    overflow_action block
    retry_max_times 5
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 60s
    retry_randomize true
    timekey 1h
    timekey_wait 10m
    <secondary>
      @type file
      path /var/log/fluentd/failed/elasticsearch_app
      compress gzip
    </secondary>
  </buffer>
</match>

# Disaster recovery - Secondary Elasticsearch cluster
<match mcp.**>
  @type elasticsearch
  @id elasticsearch_dr
  host ${ELASTICSEARCH_DR_HOST:-localhost}
  port ${ELASTICSEARCH_DR_PORT:-9200}
  user ${ELASTICSEARCH_DR_USER:-elastic}
  password ${ELASTICSEARCH_DR_PASSWORD:-changeme}
  scheme ${ELASTICSEARCH_DR_SCHEME:-http}
  ssl_verify ${ELASTICSEARCH_DR_SSL_VERIFY:-false}
  
  # DR-specific index configuration
  index_name "mcp-logs-dr-${Time.at(time).getutc.strftime('%Y.%m.%d')}"
  type_name "_doc"
  include_tag_key true
  tag_key "@tag"
  
  # DR-specific connection settings
  reload_connections true
  reconnect_on_error true
  reload_on_failure true
  pool_max 20
  pool_max_per_route 4
  idle_flush_time 60
  request_timeout 120
  
  # DR-specific buffering (less frequent)
  <buffer>
    @type file
    path /var/log/fluentd/buffer/elasticsearch_dr
    flush_mode interval
    flush_interval 60s
    chunk_limit_size 8MB
    total_limit_size 32GB
    flush_thread_count 2
    overflow_action block
    retry_max_times 3
    retry_type exponential_backoff
    retry_wait 5s
    retry_max_interval 300s
    retry_randomize true
    timekey 2h
    timekey_wait 30m
    <secondary>
      @type file
      path /var/log/fluentd/failed/elasticsearch_dr
      compress gzip
    </secondary>
  </buffer>
</match>

# Elasticsearch template creation for main logs
<match dummy>
  @type elasticsearch_template
  @id create_main_template
  host ${ELASTICSEARCH_HOST:-localhost}
  port ${ELASTICSEARCH_PORT:-9200}
  user ${ELASTICSEARCH_USER:-elastic}
  password ${ELASTICSEARCH_PASSWORD:-changeme}
  scheme ${ELASTICSEARCH_SCHEME:-http}
  ssl_verify ${ELASTICSEARCH_SSL_VERIFY:-false}
  
  template_name "mcp-logs-template"
  template_file "/etc/fluentd/templates/mcp-logs-template.json"
  overwrite true
</match>

# Elasticsearch index lifecycle management policy
<match dummy>
  @type elasticsearch_ilm
  @id create_ilm_policy
  host ${ELASTICSEARCH_HOST:-localhost}
  port ${ELASTICSEARCH_PORT:-9200}
  user ${ELASTICSEARCH_USER:-elastic}
  password ${ELASTICSEARCH_PASSWORD:-changeme}
  scheme ${ELASTICSEARCH_SCHEME:-http}
  ssl_verify ${ELASTICSEARCH_SSL_VERIFY:-false}
  
  policy_name "mcp-logs-policy"
  policy_file "/etc/fluentd/policies/mcp-logs-policy.json"
  overwrite true
</match>