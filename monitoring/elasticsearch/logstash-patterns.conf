# Logstash Configuration for EAI-MCP Platform Log Aggregation
# Advanced patterns for early incident detection and performance monitoring

input {
  # Application logs from services
  beats {
    port => 5044
    type => "application"
  }
  
  # System logs from journald
  journald {
    path => "/var/log/journal"
    type => "system"
    tags => ["system", "journald"]
  }
  
  # Docker container logs
  docker {
    host => "unix:///var/run/docker.sock"
    type => "container"
    tags => ["docker", "containers"]
  }
  
  # Prometheus alertmanager webhooks
  http {
    port => 8080
    codec => json
    type => "alert"
    tags => ["prometheus", "alerts"]
  }
}

filter {
  # Parse application logs
  if [type] == "application" {
    # Parse JSON structured logs
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
        target => "app"
      }
    }
    
    # Extract service information
    if [fields][service] {
      mutate {
        add_field => { "service_name" => "%{[fields][service]}" }
      }
    }
    
    # Parse timestamp if available
    if [app][timestamp] {
      date {
        match => [ "[app][timestamp]", "ISO8601" ]
      }
    }
    
    # Categorize log levels
    if [app][level] {
      mutate {
        add_field => { "log_level" => "%{[app][level]}" }
        lowercase => [ "log_level" ]
      }
    }
    
    # Extract performance metrics
    if [app][response_time] {
      mutate {
        convert => { "[app][response_time]" => "float" }
        add_field => { "performance_metric" => "response_time" }
      }
      
      # Flag slow responses
      if [app][response_time] > 5 {
        mutate {
          add_tag => ["slow_response", "performance_issue"]
        }
      }
    }
    
    # Extract error patterns
    if [app][error] or [log_level] == "error" {
      mutate {
        add_tag => ["error", "needs_attention"]
      }
      
      # Extract stack traces
      if [app][stack_trace] {
        mutate {
          add_field => { "error_stack" => "%{[app][stack_trace]}" }
        }
      }
      
      # Categorize error types
      if [app][error_type] {
        mutate {
          add_field => { "error_category" => "%{[app][error_type]}" }
        }
      }
    }
    
    # Extract LLM-specific metrics
    if [service_name] =~ /model|llm|ai/ {
      mutate {
        add_tag => ["llm_service"]
      }
      
      if [app][model_name] {
        mutate {
          add_field => { "llm_model" => "%{[app][model_name]}" }
        }
      }
      
      if [app][token_count] {
        mutate {
          convert => { "[app][token_count]" => "integer" }
          add_field => { "llm_tokens" => "%{[app][token_count]}" }
        }
      }
      
      if [app][context_length] {
        mutate {
          convert => { "[app][context_length]" => "integer" }
        }
        
        # Flag context overflow risks
        if [app][context_length] > 32000 {
          mutate {
            add_tag => ["context_overflow_risk"]
          }
        }
      }
    }
    
    # Extract database operation metrics
    if [app][db_query_time] {
      mutate {
        convert => { "[app][db_query_time]" => "float" }
        add_field => { "db_operation" => "query" }
      }
      
      # Flag slow queries
      if [app][db_query_time] > 1 {
        mutate {
          add_tag => ["slow_query", "database_issue"]
        }
      }
    }
    
    # Extract agent collaboration metrics
    if [service_name] =~ /agent|collaboration/ {
      mutate {
        add_tag => ["agent_system"]
      }
      
      if [app][consensus_time] {
        mutate {
          convert => { "[app][consensus_time]" => "float" }
          add_field => { "collaboration_metric" => "consensus_time" }
        }
        
        # Flag slow consensus
        if [app][consensus_time] > 60 {
          mutate {
            add_tag => ["slow_consensus", "collaboration_issue"]
          }
        }
      }
      
      if [app][collaboration_success] {
        mutate {
          add_field => { "collaboration_result" => "%{[app][collaboration_success]}" }
        }
        
        if [app][collaboration_success] == "false" {
          mutate {
            add_tag => ["collaboration_failure", "needs_attention"]
          }
        }
      }
    }
    
    # Extract HTTP request patterns
    if [app][http_method] and [app][http_status] {
      mutate {
        add_field => { 
          "http_request" => "%{[app][http_method]} %{[app][http_path]}"
          "http_status_code" => "%{[app][http_status]}"
        }
      }
      
      # Categorize HTTP status codes
      if [app][http_status] >= 500 {
        mutate {
          add_tag => ["http_5xx", "server_error", "needs_attention"]
        }
      } else if [app][http_status] >= 400 {
        mutate {
          add_tag => ["http_4xx", "client_error"]
        }
      } else if [app][http_status] >= 200 and [app][http_status] < 300 {
        mutate {
          add_tag => ["http_success"]
        }
      }
    }
    
    # Security event detection
    if [app][authentication] == "failed" or [message] =~ /(?i)unauthorized|forbidden|access denied/ {
      mutate {
        add_tag => ["security_event", "auth_failure", "needs_attention"]
      }
    }
    
    if [message] =~ /(?i)sql injection|xss|csrf|malicious/ {
      mutate {
        add_tag => ["security_threat", "critical", "needs_immediate_attention"]
      }
    }
  }
  
  # Parse system logs
  if [type] == "system" {
    # Extract systemd unit information
    if [UNIT] {
      mutate {
        add_field => { "systemd_unit" => "%{[UNIT]}" }
      }
    }
    
    # Detect service failures
    if [MESSAGE] =~ /(?i)failed|error|critical/ {
      mutate {
        add_tag => ["system_issue", "needs_attention"]
      }
    }
    
    # Monitor resource usage patterns
    if [MESSAGE] =~ /(?i)out of memory|disk full|cpu|load average/ {
      mutate {
        add_tag => ["resource_issue", "performance_issue"]
      }
    }
  }
  
  # Parse container logs
  if [type] == "container" {
    # Extract container metadata
    if [docker][container][name] {
      mutate {
        add_field => { "container_name" => "%{[docker][container][name]}" }
      }
    }
    
    if [docker][container][image] {
      mutate {
        add_field => { "container_image" => "%{[docker][container][image]}" }
      }
    }
    
    # Detect container restart patterns
    if [message] =~ /(?i)container.*restart|exit code|killed/ {
      mutate {
        add_tag => ["container_restart", "stability_issue"]
      }
    }
    
    # Monitor container resource issues
    if [message] =~ /(?i)oom|out of memory|memory limit/ {
      mutate {
        add_tag => ["container_oom", "resource_issue", "needs_attention"]
      }
    }
  }
  
  # Parse Prometheus alerts
  if [type] == "alert" {
    # Extract alert information
    if [alerts] {
      split {
        field => "alerts"
        target => "alert"
      }
      
      if [alert][labels][alertname] {
        mutate {
          add_field => { "alert_name" => "%{[alert][labels][alertname]}" }
        }
      }
      
      if [alert][labels][severity] {
        mutate {
          add_field => { "alert_severity" => "%{[alert][labels][severity]}" }
        }
      }
      
      if [alert][annotations][description] {
        mutate {
          add_field => { "alert_description" => "%{[alert][annotations][description]}" }
        }
      }
      
      mutate {
        add_tag => ["prometheus_alert", "monitoring"]
      }
      
      if [alert_severity] == "critical" {
        mutate {
          add_tag => ["critical_alert", "needs_immediate_attention"]
        }
      }
    }
  }
  
  # Add geoip information for external traffic
  if [app][client_ip] and [app][client_ip] !~ /^(10\.|192\.168\.|172\.1[6-9]\.|172\.2[0-9]\.|172\.3[0-1]\.|127\.)/ {
    geoip {
      source => "[app][client_ip]"
      target => "geoip"
    }
  }
  
  # Calculate derived metrics
  ruby {
    code => "
      # Add processing timestamp
      event.set('processing_timestamp', Time.now.utc.iso8601)
      
      # Calculate log age
      if event.get('@timestamp')
        log_age = Time.now - event.get('@timestamp').time
        event.set('log_age_seconds', log_age)
        
        # Tag stale logs
        if log_age > 300  # 5 minutes
          event.tag('stale_log')
        end
      end
    "
  }
  
  # Add custom fields for alerting
  if "needs_attention" in [tags] {
    mutate {
      add_field => { "alert_priority" => "medium" }
    }
  }
  
  if "needs_immediate_attention" in [tags] {
    mutate {
      add_field => { "alert_priority" => "high" }
    }
  }
  
  if "critical" in [tags] {
    mutate {
      add_field => { "alert_priority" => "critical" }
    }
  }
}

output {
  # Main Elasticsearch index
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "eai-mcp-logs-%{+YYYY.MM.dd}"
    template_name => "eai-mcp-logs"
    template_pattern => "eai-mcp-logs-*"
    template => {
      "index_patterns" => ["eai-mcp-logs-*"]
      "settings" => {
        "number_of_shards" => 2
        "number_of_replicas" => 1
        "index.refresh_interval" => "5s"
        "index.mapping.total_fields.limit" => 2000
      }
      "mappings" => {
        "properties" => {
          "@timestamp" => { "type" => "date" }
          "service_name" => { "type" => "keyword" }
          "log_level" => { "type" => "keyword" }
          "message" => { "type" => "text", "analyzer" => "standard" }
          "error_category" => { "type" => "keyword" }
          "performance_metric" => { "type" => "keyword" }
          "response_time" => { "type" => "float" }
          "llm_model" => { "type" => "keyword" }
          "llm_tokens" => { "type" => "integer" }
          "http_status_code" => { "type" => "keyword" }
          "alert_priority" => { "type" => "keyword" }
          "tags" => { "type" => "keyword" }
        }
      }
    }
  }
  
  # Separate index for high-priority alerts
  if "needs_immediate_attention" in [tags] or "critical" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "eai-mcp-alerts-%{+YYYY.MM.dd}"
    }
  }
  
  # Performance metrics index
  if [performance_metric] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "eai-mcp-performance-%{+YYYY.MM.dd}"
    }
  }
  
  # Security events index  
  if "security_event" in [tags] or "security_threat" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "eai-mcp-security-%{+YYYY.MM.dd}"
    }
  }
  
  # Agent collaboration metrics index
  if "agent_system" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "eai-mcp-agents-%{+YYYY.MM.dd}"
    }
  }
  
  # Debug output for development
  if [log_level] == "debug" {
    stdout { 
      codec => rubydebug 
    }
  }
}