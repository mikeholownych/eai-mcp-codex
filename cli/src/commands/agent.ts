import chalk from 'chalk';
import ora from 'ora';
import inquirer from 'inquirer';
import fs from 'fs';
import path from 'path';
import fetch from 'node-fetch';

// Import other command modules for inter-agent communication
import * as modelRouter from './model-router';
import * as planManagement from './plan-management';
import * as gitWorktree from './git-worktree';
import * as workflowOrchestrator from './workflow-orchestrator';
import * as verificationFeedback from './verification-feedback';

// Import configuration system
import { ConfigurationManager } from '../config/configuration-manager';
import { AgentDefinitionLoader, AgentDefinition, AgentExecutionContext } from '../loaders/agent-definition-loader';
import { CommandDefinitionLoader, CommandDefinition, CommandExecutionContext } from '../loaders/command-definition-loader';

// --- LLMClient Placeholder (Integrate your LLM API here) ---
// This class is responsible for making actual requests to your chosen LLM (e.g., OpenAI, Google Gemini).
// You will need to replace the placeholder methods with actual API calls.
class LLMClient {
  private apiUrl: string;
  private model: string;

  constructor() {
    // Use the llm-router endpoint
    this.apiUrl = process.env.LLM_ROUTER_URL || 'http://localhost:8000/query';
    this.model = process.env.LLM_MODEL || 'deepseek-coder:6.7b'; // Default model for llm-router

    console.log(chalk.gray(`[LLMClient] Using LLM Router API URL: ${this.apiUrl}, Model: ${this.model}`));
  }

  async generateText(prompt: string): Promise<string> {
    console.log(chalk.gray(`\n[LLMClient] Sending prompt to LLM Router:\n${prompt.substring(0, 200)}...`));
    try {
      const response = await fetch(this.apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          query: prompt,
          model: this.model, // Pass model to llm-router
          max_tokens: 2048, // Increased max tokens for more complex responses
          temperature: 0.7
        }),
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(`LLM Router API error: ${response.status} ${response.statusText} - ${JSON.stringify(errorData)}`);
      }

      const data: any = await response.json();
      // The llm-router /query endpoint returns a 'response' field
      const generatedContent = data.response || '';
      console.log(chalk.gray(`[LLMClient] Received response (first 200 chars):\n${generatedContent.substring(0, 200)}...`));
      return generatedContent;
    } catch (error: any) {
      console.error(chalk.red(`[LLMClient] Error during LLM Router API call: ${error.message}`));
      throw error;
    }
  }
}

// --- Enhanced AgentClient with Configuration Support ---
export class AgentClient {
  public llmClient: LLMClient;
  private configManager: ConfigurationManager;
  private agentLoader: AgentDefinitionLoader;
  private commandLoader: CommandDefinitionLoader;

  constructor() {
    this.llmClient = new LLMClient();
    this.configManager = new ConfigurationManager({
      logLevel: 'info',
      enableCaching: true,
      conflictResolution: 'merge',
      validationLevel: 'basic',
    });
    this.agentLoader = new AgentDefinitionLoader(this.configManager);
    this.commandLoader = new CommandDefinitionLoader(this.configManager);
  }

  /**
   * Create a plan using configuration-aware agent
   */
  async createPlan(task: string, agentName?: string): Promise<any> {
    try {
      // Load planner agent configuration
      const plannerAgent = agentName 
        ? await this.agentLoader.loadAgentDefinition(agentName)
        : await this.findBestPlannerAgent();

      if (!plannerAgent) {
        console.log(chalk.yellow('No planner agent configuration found, using default behavior'));
        return this.createPlanDefault(task);
      }

      console.log(chalk.blue(`Using planner agent: ${plannerAgent.frontMatter.name}`));

      // Create execution context
      const context = this.agentLoader.createExecutionContext(plannerAgent, {
        parentTask: task,
        executionEnvironment: 'development',
      });

      // Build enhanced prompt with agent instructions
      const enhancedPrompt = this.buildEnhancedPrompt(task, plannerAgent, context);
      
      const planText = await this.llmClient.generateText(enhancedPrompt);
      
      try {
        const plan = JSON.parse(planText);
        if (!Array.isArray(plan)) {
          throw new Error('LLM did not return a JSON array for the plan.');
        }
        
        return {
          id: `plan-${Date.now()}`,
          task,
          agent: plannerAgent.frontMatter.name,
          steps: plan,
          context: context,
          createdAt: new Date(),
        };
      } catch (parseError: any) {
        console.error(chalk.red(`Failed to parse plan from LLM: ${parseError.message}`));
        // Fallback to default planning
        return this.createPlanDefault(task);
      }
    } catch (error: any) {
      console.error(chalk.red(`Error in configuration-aware planning: ${error.message}`));
      // Fallback to default planning
      return this.createPlanDefault(task);
    }
  }

  /**
   * Default plan creation (fallback)
   */
  private async createPlanDefault(task: string): Promise<any> {
    const prompt = `You are an AI assistant tasked with creating a step-by-step plan to accomplish the following task: \"${task}\".\n\nProvide a detailed plan as a JSON array of steps. Each step should be an object with a \"command\" field (matching CLI commands like \"generate\", \"refactor\", \"verify\", \"plan_create\", \"git_create\") and an \"args\" object containing the arguments for that command.\n\nExample Plan for \"Create a new React component called MyButton in src/components/MyButton.tsx and verify it\":\n[\n  {\"command\": \"generate\", \"args\": {\"prompt\": \"React functional component MyButton\", \"filePath\": \"src/components/MyButton.tsx\"}},\n  {\"command\": \"verify\", \"args\": {\"filePath\": \"src/components/MyButton.tsx\"}}\n]\n\nYour plan for \"${task}\":`;

    const planText = await this.llmClient.generateText(prompt);
    try {
      const plan = JSON.parse(planText);
      if (!Array.isArray(plan)) {
        throw new Error('LLM did not return a JSON array for the plan.');
      }
      return {
        id: `plan-${Date.now()}`,
        task,
        steps: plan
      };
    } catch (error: any) {
      console.error(chalk.red(`Failed to parse plan from LLM: ${error.message}. Raw response:\n${planText}`));
      throw new Error('Invalid plan format from LLM.');
    }
  }

  /**
   * Find the best planner agent
   */
  private async findBestPlannerAgent(): Promise<AgentDefinition | null> {
    try {
      const plannerAgents = await this.agentLoader.loadAgentDefinitionsByType('planner');
      
      if (plannerAgents.length === 0) {
        return null;
      }

      // Return the highest priority planner agent
      return plannerAgents.sort((a, b) => (b.frontMatter.priority || 0) - (a.frontMatter.priority || 0))[0];
    } catch (error) {
      console.error(chalk.yellow(`Warning: Could not load planner agents: ${error instanceof Error ? error.message : String(error)}`));
      return null;
    }
  }

  /**
   * Build enhanced prompt with agent instructions
   */
  private buildEnhancedPrompt(task: string, agent: AgentDefinition, context: AgentExecutionContext): string {
    let prompt = '';

    // Add system prompt if available
    if (agent.systemPrompt) {
      prompt += `${agent.systemPrompt}\n\n`;
    }

    // Add agent instructions
    prompt += `${agent.instructions}\n\n`;

    // Add task-specific context
    prompt += `Task: ${task}\n\n`;

    // Add capabilities context
    if (agent.capabilities.length > 0) {
      prompt += `Available capabilities: ${agent.capabilities.join(', ')}\n\n`;
    }

    // Add constraints
    if (agent.constraints && agent.constraints.length > 0) {
      prompt += `Constraints:\n${agent.constraints.map(c => `- ${c}`).join('\n')}\n\n`;
    }

    // Add planning instructions
    prompt += `Create a detailed step-by-step plan as a JSON array. Each step should have:
- "command": The CLI command to execute
- "args": Object with command arguments
- "description": Brief description of what this step accomplishes

Available commands: generate, refactor, verify, plan_create, git_create, workflow_create, etc.

Example format:
[
  {
    "command": "generate",
    "args": {"prompt": "description", "filePath": "path"},
    "description": "Generate code file"
  }
]

Your plan:`;

    return prompt;
  }

  async executePlan(plan: any): Promise<any> {
    console.log(chalk.blue.bold(`\n‚ñ∂Ô∏è  Executing plan: ${plan.id} - ${plan.task}\n`));

    for (const step of plan.steps) {
      const spinner = ora(`Executing step: ${step.command} with args ${JSON.stringify(step.args)}`).start();
      try {
        await this.dispatchCommand(step.command, step.args);
        spinner.succeed(`Step completed: ${step.command}`);
      } catch (error: any) {
        spinner.fail(`Step failed: ${step.command} - ${error.message}`);
        throw error; // Stop execution if a step fails
      }
    }
    console.log(chalk.green.bold('\n‚úÖ Plan executed successfully!'));
    return { status: 'completed' };
  }

  public async dispatchCommand(command: string, args: any): Promise<void> {
    try {
      // Try to load command configuration
      const commandDef = await this.commandLoader.loadCommandDefinition(command);
      
      if (commandDef) {
        console.log(chalk.blue(`Using configured command: ${commandDef.frontMatter.name}`));
        await this.executeConfiguredCommand(commandDef, args);
      } else {
        // Fallback to hardcoded command execution
        await this.executeHardcodedCommand(command, args);
      }
    } catch (error: any) {
      console.error(chalk.red(`Command execution failed: ${error.message}`));
      throw error;
    }
  }

  /**
   * Execute a configured command with validation and context
   */
  private async executeConfiguredCommand(commandDef: CommandDefinition, args: any): Promise<void> {
    // Validate parameters
    const validation = this.commandLoader.validateCommandParameters(commandDef, args);
    
    if (!validation.isValid) {
      const errorMessages = validation.errors.map(e => `${e.parameter}: ${e.message}`).join('\n');
      throw new Error(`Parameter validation failed:\n${errorMessages}`);
    }

    // Show warnings if any
    if (validation.warnings.length > 0) {
      validation.warnings.forEach(warning => {
        console.log(chalk.yellow(`Warning: ${warning.parameter}: ${warning.message}`));
      });
    }

    // Create execution context
    const context = this.commandLoader.createExecutionContext(
      commandDef,
      validation.normalizedParameters,
      {
        workingDirectory: process.cwd(),
        executionEnvironment: 'development',
      }
    );

    // Execute pre-execution checks
    if (commandDef.executionSettings.preExecutionChecks.length > 0) {
      console.log(chalk.gray('Running pre-execution checks...'));
      await this.runPreExecutionChecks(commandDef.executionSettings.preExecutionChecks, context);
    }

    // Execute the command based on its type
    switch (commandDef.type) {
      case 'generation':
        await this.executeGenerationCommand(commandDef, context);
        break;
      case 'refactoring':
        await this.executeRefactoringCommand(commandDef, context);
        break;
      case 'analysis':
        await this.executeAnalysisCommand(commandDef, context);
        break;
      case 'testing':
        await this.executeTestingCommand(commandDef, context);
        break;
      case 'deployment':
        await this.executeDeploymentCommand(commandDef, context);
        break;
      default:
        // Fallback to hardcoded execution
        await this.executeHardcodedCommand(commandDef.frontMatter.name, args);
    }

    // Execute post-execution actions
    if (commandDef.executionSettings.postExecutionActions.length > 0) {
      console.log(chalk.gray('Running post-execution actions...'));
      await this.runPostExecutionActions(commandDef.executionSettings.postExecutionActions, context);
    }
  }

  /**
   * Execute hardcoded commands (fallback)
   */
  private async executeHardcodedCommand(command: string, args: any): Promise<void> {
    switch (command) {
      case 'generate':
        await this.generateCode(args.prompt, args.filePath);
        break;
      case 'refactor':
        await this.refactorCode(args.filePath, args.prompt);
        break;
      case 'verify':
        await this.verifyCodeChanges(args.filePath);
        break;
      case 'model_route':
        await modelRouter.route(args.prompt, args.options || {});
        break;
      case 'model_list':
        await modelRouter.listModels();
        break;
      case 'plan_create':
        await planManagement.create(args.title, { description: args.description, tags: args.tags });
        break;
      case 'plan_list':
        await planManagement.list({});
        break;
      case 'plan_show':
        await planManagement.show(args.planId);
        break;
      case 'plan_update':
        await planManagement.update(args.planId, { status: args.status });
        break;
      case 'git_create':
        await gitWorktree.create(args.repo, args.branch, { path: args.path });
        break;
      case 'git_list':
        await gitWorktree.list();
        break;
      case 'git_remove':
        await gitWorktree.remove(args.worktreeId);
        break;
      case 'workflow_create':
        await workflowOrchestrator.create(args.name, { steps: args.steps });
        break;
      case 'workflow_execute':
        await workflowOrchestrator.execute(args.workflowId);
        break;
      case 'workflow_status':
        await workflowOrchestrator.status(args.workflowId);
        break;
      case 'verify_submit':
        await verificationFeedback.submit(args.type, args.title, { description: args.description, severity: args.severity });
        break;
      case 'verify_list':
        await verificationFeedback.list();
        break;
      case 'verify_show':
        await verificationFeedback.show(args.feedbackId);
        break;
      default:
        throw new Error(`Unknown command: ${command}`);
    }
  }

  /**
   * Configuration-aware command execution methods
   */
  
  private async executeGenerationCommand(commandDef: CommandDefinition, context: CommandExecutionContext): Promise<void> {
    const { prompt, filePath } = context.parameters;
    
    // Build enhanced prompt with command instructions
    const enhancedPrompt = this.buildCommandPrompt(commandDef, context);
    const generatedContent = await this.llmClient.generateText(enhancedPrompt);
    
    // Apply output formatting based on command configuration
    const formattedContent = this.formatOutput(generatedContent, commandDef.outputFormat);
    
    fs.writeFileSync(filePath, formattedContent);
    console.log(chalk.green(`‚úÖ Generated code saved to ${filePath}`));
  }

  private async executeRefactoringCommand(commandDef: CommandDefinition, context: CommandExecutionContext): Promise<void> {
    const { filePath, prompt } = context.parameters;
    
    if (!fs.existsSync(filePath)) {
      throw new Error(`File not found: ${filePath}`);
    }

    const originalContent = fs.readFileSync(filePath, 'utf8');
    
    // Build enhanced prompt with command instructions and original code
    const enhancedPrompt = this.buildRefactoringPrompt(commandDef, context, originalContent);
    
    const refactoredContent = await this.llmClient.generateText(enhancedPrompt);
    const formattedContent = this.formatOutput(refactoredContent, commandDef.outputFormat);
    
    fs.writeFileSync(filePath, formattedContent);
    console.log(chalk.green(`‚úÖ Refactored code saved to ${filePath}`));
  }

  private async executeAnalysisCommand(commandDef: CommandDefinition, context: CommandExecutionContext): Promise<void> {
    const { filePath } = context.parameters;
    
    if (!fs.existsSync(filePath)) {
      throw new Error(`File not found: ${filePath}`);
    }

    const content = fs.readFileSync(filePath, 'utf8');
    const enhancedPrompt = this.buildAnalysisPrompt(commandDef, context, content);
    
    const analysis = await this.llmClient.generateText(enhancedPrompt);
    
    console.log(chalk.blue.bold('\nüìä Code Analysis Results:'));
    console.log(this.formatOutput(analysis, commandDef.outputFormat));
  }

  private async executeTestingCommand(commandDef: CommandDefinition, context: CommandExecutionContext): Promise<void> {
    const { filePath } = context.parameters;
    
    console.log(chalk.blue(`üß™ Running tests for ${filePath}...`));
    
    // Enhanced testing with command configuration
    const testPrompt = this.buildTestingPrompt(commandDef, context);
    
    if (testPrompt) {
      const testSuggestions = await this.llmClient.generateText(testPrompt);
      console.log(chalk.yellow.bold('\nüí° Test Suggestions:'));
      console.log(this.formatOutput(testSuggestions, commandDef.outputFormat));
    }
    
    // Run actual verification (fallback to existing method)
    await this.verifyCodeChanges(filePath);
  }

  private async executeDeploymentCommand(commandDef: CommandDefinition, context: CommandExecutionContext): Promise<void> {
    console.log(chalk.blue('üöÄ Preparing deployment...'));
    
    const deploymentPrompt = this.buildDeploymentPrompt(commandDef, context);
    const deploymentPlan = await this.llmClient.generateText(deploymentPrompt);
    
    console.log(chalk.blue.bold('\nüìã Deployment Plan:'));
    console.log(this.formatOutput(deploymentPlan, commandDef.outputFormat));
    
    // Note: Actual deployment would require additional infrastructure integration
    console.log(chalk.yellow('\n‚ö†Ô∏è  Note: Actual deployment execution requires additional configuration'));
  }

  /**
   * Helper methods for building enhanced prompts
   */
  
  private buildCommandPrompt(commandDef: CommandDefinition, context: CommandExecutionContext): string {
    let prompt = '';
    
    // Add command instructions
    prompt += `${commandDef.instructions}\n\n`;
    
    // Add specific parameters context
    const { prompt: userPrompt, filePath } = context.parameters;
    prompt += `Task: ${userPrompt}\n`;
    prompt += `Target file: ${filePath}\n\n`;
    
    // Add constraints from configuration
    if (commandDef.contextRequirements.requiredContext.length > 0) {
      prompt += `Required context: ${commandDef.contextRequirements.requiredContext.join(', ')}\n\n`;
    }
    
    prompt += `Generate ${commandDef.outputFormat} output for the requested task.`;
    
    return prompt;
  }

  private buildRefactoringPrompt(commandDef: CommandDefinition, context: CommandExecutionContext, originalCode: string): string {
    let prompt = '';
    
    prompt += `${commandDef.instructions}\n\n`;
    prompt += `Refactoring task: ${context.parameters.prompt}\n\n`;
    prompt += `Original code:\n\`\`\`\n${originalCode}\n\`\`\`\n\n`;
    prompt += `Please refactor the code according to the task requirements. Return only the refactored code.`;
    
    return prompt;
  }

  private buildAnalysisPrompt(commandDef: CommandDefinition, context: CommandExecutionContext, code: string): string {
    let prompt = '';
    
    prompt += `${commandDef.instructions}\n\n`;
    prompt += `Code to analyze:\n\`\`\`\n${code}\n\`\`\`\n\n`;
    prompt += `Provide a comprehensive analysis of the code including:
- Code quality assessment
- Potential issues or bugs
- Performance considerations
- Security vulnerabilities
- Suggestions for improvement`;
    
    return prompt;
  }

  private buildTestingPrompt(commandDef: CommandDefinition, context: CommandExecutionContext): string | null {
    if (!context.parameters.filePath) return null;
    
    let prompt = '';
    
    prompt += `${commandDef.instructions}\n\n`;
    prompt += `File to test: ${context.parameters.filePath}\n\n`;
    prompt += `Generate comprehensive test suggestions including:
- Unit test cases
- Edge cases to consider
- Integration test scenarios
- Performance test recommendations`;
    
    return prompt;
  }

  private buildDeploymentPrompt(commandDef: CommandDefinition, context: CommandExecutionContext): string {
    let prompt = '';
    
    prompt += `${commandDef.instructions}\n\n`;
    prompt += `Create a deployment plan that includes:
- Pre-deployment checklist
- Deployment steps
- Post-deployment verification
- Rollback procedures
- Monitoring recommendations`;
    
    return prompt;
  }

  private formatOutput(content: string, format: string): string {
    switch (format) {
      case 'json':
        try {
          return JSON.stringify(JSON.parse(content), null, 2);
        } catch {
          return content; // Return as-is if not valid JSON
        }
      case 'markdown':
        return content; // Already markdown format
      case 'code':
        return content.replace(/^```[\w]*\n?/, '').replace(/\n?```$/, '');
      case 'plain':
      default:
        return content;
    }
  }

  /**
   * Execution lifecycle methods
   */
  
  private async runPreExecutionChecks(checks: string[], context: CommandExecutionContext): Promise<void> {
    for (const check of checks) {
      switch (check.toLowerCase()) {
        case 'validate parameters':
          // Already done during parameter validation
          console.log(chalk.gray('  ‚úì Parameters validated'));
          break;
        case 'check permissions':
          await this.checkPermissions(context);
          break;
        case 'verify working directory':
          await this.verifyWorkingDirectory(context);
          break;
        default:
          console.log(chalk.gray(`  ‚ö† Unknown check: ${check}`));
      }
    }
  }

  private async runPostExecutionActions(actions: string[], context: CommandExecutionContext): Promise<void> {
    for (const action of actions) {
      switch (action.toLowerCase()) {
        case 'validate outputs':
          await this.validateOutputs(context);
          break;
        case 'clean up temporary files':
          await this.cleanupTempFiles(context);
          break;
        case 'log execution results':
          await this.logExecutionResults(context);
          break;
        default:
          console.log(chalk.gray(`  ‚ö† Unknown action: ${action}`));
      }
    }
  }

  private async checkPermissions(context: CommandExecutionContext): Promise<void> {
    // Basic permission checks
    if (context.securityContext.permissions.length > 0) {
      console.log(chalk.gray(`  ‚úì Permissions checked: ${context.securityContext.permissions.join(', ')}`));
    } else {
      console.log(chalk.gray('  ‚úì No special permissions required'));
    }
  }

  private async verifyWorkingDirectory(context: CommandExecutionContext): Promise<void> {
    if (fs.existsSync(context.workingDirectory)) {
      console.log(chalk.gray(`  ‚úì Working directory verified: ${context.workingDirectory}`));
    } else {
      throw new Error(`Working directory not found: ${context.workingDirectory}`);
    }
  }

  private async validateOutputs(context: CommandExecutionContext): Promise<void> {
    // Basic output validation
    console.log(chalk.gray('  ‚úì Outputs validated'));
  }

  private async cleanupTempFiles(context: CommandExecutionContext): Promise<void> {
    // Cleanup logic would go here
    console.log(chalk.gray('  ‚úì Temporary files cleaned'));
  }

  private async logExecutionResults(context: CommandExecutionContext): Promise<void> {
    console.log(chalk.gray(`  ‚úì Execution logged for command: ${context.command.frontMatter.name}`));
  }

  async generateCode(prompt: string, filePath: string): Promise<string> {
    const llmPrompt = `Generate code based on the following prompt: \"${prompt}\".\nProvide only the code, no explanations or extra text.`;
    const generatedContent = await this.llmClient.generateText(llmPrompt);
    fs.writeFileSync(filePath, generatedContent);
    return generatedContent;
  }

  async refactorCode(filePath: string, prompt: string): Promise<string> {
    const originalContent = fs.readFileSync(filePath, 'utf8');
    const llmPrompt = `Refactor the following code from file \"${filePath}\" based on this instruction: \"${prompt}\".\n\nOriginal Code:\n\`\`\`\n${originalContent}\n\`\`\`\n\nProvide only the refactored code, no explanations or extra text.`;
    const refactoredContent = await this.llmClient.generateText(llmPrompt);
    fs.writeFileSync(filePath, refactoredContent);
    return refactoredContent;
  }

  async verifyCodeChanges(filePath: string): Promise<boolean> {
    const spinner = ora(`Running tests and linting for ${filePath}...`).start();
    // In a real scenario, you\'d run actual tests and linting tools here.\n    await new Promise(resolve => setTimeout(resolve, 2000)); // Simulate testing
    const success = Math.random() > 0.2; // 80% chance of success
    if (success) {
      spinner.succeed(`Verification passed for ${filePath}!`);
    } else {
      spinner.fail(`Verification failed for ${filePath}. Please check the code.`);
    }
    return success;
  }
}

export async function plan(task: string) {
  console.log(chalk.blue.bold('ü§ñ Generating a plan for your task...\n'));

  const client = new AgentClient();
  const spinner = ora('Analyzing task and creating plan...').start();

  try {
    const plan = await client.createPlan(task);
    spinner.succeed('Plan created successfully!');

    console.log(chalk.green.bold('\nüìù Plan Details:'));
    console.log(`ID: ${chalk.cyan(plan.id)}`);
    console.log(`Task: ${chalk.white(plan.task)}`);

    console.log(chalk.yellow.bold('\nüìã Steps:'));
    plan.steps.forEach((step: any, index: number) => {
      console.log(`${index + 1}. Command: ${step.command}, Args: ${JSON.stringify(step.args)}`);
    });

    const { confirm } = await inquirer.prompt([
      {
        type: 'confirm',
        name: 'confirm',
        message: 'Do you want to execute this plan?',
        default: false
      }
    ]);

    if (confirm) {
      await execute(plan);
    }

  } catch (error: any) {
    spinner.fail(`Failed to create plan: ${error.message}`);
    process.exit(1);
  }
}

export async function execute(plan: any) {
  console.log(chalk.blue.bold(`\n‚ñ∂Ô∏è  Executing plan: ${plan.id}\n`));

  const client = new AgentClient();

  try {
    const result = await client.executePlan(plan);
    console.log(chalk.green.bold('\n‚úÖ Plan executed successfully!'));
    console.log(`Status: ${result.status}`);
  } catch (error: any) {
    console.error(chalk.red(`Failed to execute plan: ${error.message}`));
    process.exit(1);
  }
}

export async function generate(prompt: string, filePath: string) {
  console.log(chalk.blue.bold('ü§ñ Generating code...\n'));

  const client = new AgentClient();
  const spinner = ora('Generating code...').start();

  try {
    const code = await client.generateCode(prompt, filePath);
    spinner.succeed(`Code generated successfully to ${filePath}!`);

    console.log(chalk.green.bold('\nGenerated Code:'));
    console.log(chalk.white(code));

  } catch (error: any) {
    spinner.fail(`Failed to generate code: ${error.message}`);
    process.exit(1);
  }
}

export async function refactor(filePath: string, prompt: string) {
  console.log(chalk.blue.bold('ü§ñ Refactoring code...\n'));

  const client = new AgentClient();
  const spinner = ora('Refactoring code...').start();

  try {
    const code = await client.refactorCode(filePath, prompt);
    spinner.succeed(`Code refactored successfully in ${filePath}!`);

    console.log(chalk.green.bold('\nRefactored Code:'));
    console.log(chalk.white(code));

  } catch (error: any) {
    spinner.fail(`Failed to refactor code: ${error.message}`);
    process.exit(1);
  }
}

export async function verify(filePath: string) {
  console.log(chalk.blue.bold(`ü§ñ Verifying code changes in ${filePath}...\n`));

  const client = new AgentClient();

  try {
    const success = await client.verifyCodeChanges(filePath);
    if (success) {
      console.log(chalk.green.bold('\n‚úÖ Code verification passed!'));
    } else {
      console.log(chalk.red.bold('\n‚ùå Code verification failed. Please review the output above.'));
    }
  } catch (error: any) {
    console.error(chalk.red(`Failed to verify code: ${error.message}`));
    process.exit(1);
  }
}